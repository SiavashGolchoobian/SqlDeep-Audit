<PerformanceCounterDataCollector>
    <Counter>\%instance%:Access Methods\Extents Allocated/sec</Counter>
	<Counter>\%instance%:Access Methods\Page Splits/sec</Counter>					<!--**Disk Performance: The number of page splits per second that occurs as the result of overflowing index pages and new page allocations.This value should be as low as possible. Heavily fragmented indexes may be the result of high page splits/sec.A ratio of should not be more than 1 page split for every 20 batch requests (should less than 5% of Batch Requests/sec). If the number of page splits is high, consider increasing the fillfactor of your indexes. An increased fillfactor helps to reduce page splits by increasing the amount of free space on each page. (Source:PAL)-->
	<Counter>\%instance%:Access Methods\Scan Point Revalidations/sec</Counter>		<!--**SQL Pressure: High number of Scan Point Revalidations/sec potentially indicate hot spots in the data, probably due to a poor choice of clustered index putting the most active rows on the same page. Resolution: isolating reporting and application use, and most importantly ensuring that the clustered index choice is the right one. Clustered indexes should be on columns that are sorted on, grouped on, used in joins, used in between queries, and in other operations where the order of the returned data is critical. (Source:PAL)-->
	<Counter>\%instance%:Access Methods\Pages Allocated/sec</Counter>
	<Counter>\%instance%:Access Methods\Forwarded Records/sec</Counter>				<!--**Disk Performance: (semi equal to [forwarded_record_count from sys.dm_db_index_physical_stats]) This value should be less than 10% of the number of Batch Requests/Sec. Forwarded Records only occurs on heaps which are tables without clustered indexes. If a table has lots of forwarded records, scanning the table can be very inefficient, to resolving this issue: Evaluate clustered indexes for heap tables, Using default values so that an update does not result in a longer row that is the root cause of forwarded records, Using Char instead of Varchar. Using Char creates a fixed length so that an update does not result in a longer row, In cases where clustered indexes cannot be used, drop non-clustered indexes, build a clustered index to reorganize pages and rows, drop the clustered index, and then recreate non-clustered indexes. (Source:PAL)-->
	<Counter>\%instance%:Access Methods\FreeSpace Scans/sec</Counter>				<!--**CPU Pressure: not more than 1 freespace scan for every 10 Batch Requests/Sec (10%), it cause Unexplained high CPU usage by SQL Server, sometimes up to 100%. FreeSpace Scans/sec represents inserts into a table with no physical ordering of its rows which is called a heap. Microsoft recommends that you add a clustered index to the table and test the effect of the clustered index on performance. (Source:PAL)-->
	<Counter>\%instance%:Access Methods\Full Scans/sec</Counter>					<!--**CPU Performance + Memory Performance: Scans are not necessarily a bad thing. But they do represent a broader access of data, so they are likely to indicate a problems like: Missing indexes, Too many rows requested, Not selective enough a predicate, Improper T-SQL, Data distribution or quantity doesn’t support a seek. As a result of  this event you may also see high waits for the ASYNC_IO_COMPLETION, IO_COMPLETION, PAGEIOLATCH_*. The ratio of Full Scans/sec to Index Searches/sec should not bigger than 1 to 1000 (0.001). (Source:PAL)-->
	<Counter>\%instance%:Access Methods\Index Searches/sec</Counter>				<!--SQL Pressure: A ratio of more than 1 SQL Full Scan for every 1000 Index Searches (Source:PAL)-->
	<Counter>\%instance%:Access Methods\Table Lock Escalations/sec</Counter>		<!--SQL Pressure: The number of times locks on a table were escalated from page- or row-level to table-level. Frequent or even occasional spiking in this value may indicate poorly coded transactions. ock escalation is triggered when lock escalation is not disabled on the table by using the ALTER TABLE SET LOCK_ESCALATION option, and when either of the following conditions exists: A single Transact-SQL statement acquires at least 5,000 locks on a single nonpartitioned table or index, A single Transact-SQL statement acquires at least 5,000 locks on a single partition of a partitioned table and the ALTER TABLE SET LOCK_ESCALATION option is set to AUTO, The number of locks in an instance of the Database Engine exceeds memory or configuration thresholds. Solution: READ COMMITTED isolation level when the READ_COMMITTED_SNAPSHOT database option is ON, SNAPSHOT isolation level, READ UNCOMMITTED isolation level. This can only be used for systems that can operate with dirty reads. This value should not be greater than 500. (Source:PAL)-->
	<Counter>\%instance%:Access Methods\Worktables Created/sec</Counter>			<!--**SQL Pressure: Number of work tables created per second. For example, work tables could be used to store temporary results for query spool, LOB variables, XML variables, and cursors. Solution: Look for expensive statements with high CPU, duration, and statements that run in parallel and tune them by adding indexes, reducing the volume of data being returned, and adding indexes where appropriate,Ensure that TempDB is not a bottleneck and is following best practices,Additionally consider putting TempDB on local SSD disks in order to maximize disk performance. This value should not Greater than 20 Worktables created per second. (Source:PAL)-->
	<Counter>\%instance%:Access Methods\Workfiles Created/sec</Counter>				<!--**SQL Pressure + Disk Performance: Hash joins can require large amounts of memory for execution. As part of executing a hash join, the memory required for the hash can become too large and require a spill to disk. The disk storage to backup the hash operation is called a workfile. Workfiles are collections of extents and pages that are managed strictly by the workfile code. Solution: look for expensive queries and consider rewriting them, and add as last resort consider adding additional memory. This counter should not Greater than 20 Workfiles created per second. (Source:PAL)-->
	<Counter>\%instance%:SQL Statistics\Batch Requests/sec</Counter>				<!--**CPU Performance: SQL command batches received per second, over 1000 and mostly 10,000 requests in a second would be considered a busy system. This counter is a good indicator of the load on SQL Server, Based on the level of system resource utilization and Batch Requests/sec, you can estimate the number of users SQL Server may be able to take without developing resource bottlenecks, also This counter value, at different load cycles, helps you understand its relationship with the number of database connection. (Source:PAL)-->
	<Counter>\%instance%:SQL Statistics\Compilations/sec</Counter>					<!--**CPU Performance: Number of SQL compilations that occured per second that includes recompiles. A high value subtracting recompiles can be an indication of a large number of ad hoc queries that can also be cross referenced with the number of ad hoc plans in the plan cache counter. Should not greater than 1 SQL Compilation for every 10 Batch Requests per second. (Source:PAL)-->
	<Counter>\%instance%:SQL Statistics\Recompilations/sec</Counter>				<!--**CPU Performance: Number of SQL re-compiles per second that measures the number of times that a statement executed, but had to be compiled again before the statement completed. There are a variety of reasons that a recompile occured such as statistics being out of date, an column was added to a table a store procedure depends on, statement was run with a recompile option, etc. This counter needs to be as close to 0 as possible. A recompile can cause deadlocks and compile locks that are not compatible with any locking type.SQL Server Trace / Profiler provides an execellent way to find out exactly why recompiles are occuring in your environment.Should not greater than 1 SQL Re-Compilation for every 10 SQL Compilations. (Source:PAL)-->
	<Counter>\%instance%:SQL Statistics\Auto-Param Attempts/sec</Counter>			<!--**CPU Performance: Number of auto-parameterization attempts. (Source:PAL)-->
    <Counter>\%instance%:Buffer Manager\Page life expectancy</Counter>				<!--**Memory Performance + Disk Performance: (equal to [DBCC MEMORYSTATUS]>[Buffer Pool section]>[Page Life Expectancy]), Number of seconds a page will stay in the buffer pool without references. Page Life Expectancy over 1000 is very good (no pressure on memory) but below 1000 is risky and below 300 is very bad also Any large drops of 30% or more should be investigated. When page life expectancy becomes low, then SQL Server will respond by sweeping through the buffer pool using the lazy writer, increasing lazy writer activity. Low page life expectancy may cause more physical reads increasing pressure on disk and slowing down SQL Server responsiveness. Solution: look for queries with a high number of logical reads and consider tuning and potentially rewriting them, and potentially add additional memory if non-hardware options to not address the issue. (Source:PAL)-->
	<Counter>\%instance%:Buffer Manager\Buffer cache hit ratio</Counter>			<!--**Memory Performance + Disk Performance: (equal to [(Logical Reads - Physical Reads)/Logical Reads])The Buffer Cache Hit Ratio counter is specific to an application. However, a rate of 90 percent or higher is desirable. Solution: look for queries with a high number of logical reads and consider tuning and potentially rewriting them or Add more memory until the value is consistently greater than 90 percent (under 90% is not acceptable) and over 97% is perfect. A value greater than 90 percent indicates that more than 90 percent of all requests for data were satisfied from the data cache. (Source:PAL)-->
	<Counter>\%instance%:Buffer Manager\Checkpoint pages/sec</Counter>				<!--Memory Performance:-->
	<Counter>\%instance%:Buffer Manager\Free pages</Counter>						<!--**Memory Performance: Total number of pages on all free lists. The more free pages that are available then the less often the lazy writer will have to fire keeping pages in the buffer pool longer. The higher the Buffer Manager\Free pages then the higher the Buffer Manager\Page Life Expectancy should be. If Buffer Manager\Free pages is low then the Buffer Manager\Lazy Writes /sec will be higher as the Lazy Writer will become active attempting to free the buffer cache as SQL Server will be under memory pressure. A value less than 640 (or 5 MB) may indicate physical memory pressure. (Source:PAL)-->
	<Counter>\%instance%:Buffer Manager\Lazy writes/sec</Counter>					<!--**Memory Performance + Disk Performance: This counter tracks how many times a second that the Lazy Writer process is moving dirty pages from the buffer to disk in order to free up buffer space. This process is where the dirty, aged buffers are removed from the buffer by a system process. High value on this counter possibly indicates I/O issues or even SQL Server memory problems. The Lazy writes / sec values should consistently be less than 20 for the average system. (Source:PAL)-->
	<Counter>\%instance%:Buffer Manager\Page reads/sec</Counter>					<!--**Disk Performance: number of pages being read from physical disk into the buffer manager per secod. This value should be below 90, anything that is above indicates indexing or memory constraint. Solution: Tune IO intensive queries, Change Fillfactor to highest value (Before adjusting the fill factor, at a database level compare the SQL Server:Buffer Manager\Page reads/sec counter to the SQL Server:Buffer Manager\Page writes/sec counter, and use the fill factor option only if writes are a substantial fraction of reads (greater than 30 percent)). (Source:PAL)-->
	<Counter>\%instance%:Buffer Manager\Page writes/sec</Counter>					<!--**Disk Performance: number of pages being written out of the buffer manager to physical disk per second. This value should be below 90, Anything above 90, it is recommended to check the lazy writer/sec and Checkpoint pages/sec counter, if these counters are also relatively high then, this indicates a memory constraint. Solution: Tune IO intensive queries, Change Fillfactor to highest value (Before adjusting the fill factor, at a database level compare the SQL Server:Buffer Manager\Page reads/sec counter to the SQL Server:Buffer Manager\Page writes/sec counter, and use the fill factor option only if writes are a substantial fraction of reads (greater than 30 percent)). (Source:PAL)-->
	<Counter>\%instance%:Buffer Manager\Page lookups/sec</Counter>					<!--SQL Pressure: Page Lookups/sec is the number of requests to find a page in the buffer pool made per second. If this number is high as compared to the number of batch requests, this indicates a degree of inefficiency and a potential opportunity for tuning. Solution: Identify queries with the highest amount of logical I/O's and tune them. Ratio of Page Lookups/sec to Batch Requests/sec should be less than 100. (Source:PAL)-->
	<Counter>\%instance%:Buffer Manager\Database pages</Counter>					<!--Memory Performance: Indication of SQL Server whole Buffer Pool space pages-->
	<Counter>\%instance%:Buffer Manager\Target pages</Counter>						<!--Memory Performance: Indicates the total amount of pages that SQL Server Buffer Pool cache is willing to consume-->
	<Counter>\%instance%:Plan Cache(*)\Cache Hit Ratio</Counter>					<!--Memory Performance: Ratio between cache hits and lookups. -->
	<Counter>\%instance%:Buffer Node\Page life expectancy</Counter>					<!--Memory Performance: is like [Buffer Manager\Page life expectancy] but measure based on each NUMA memory-->
	<Counter>\%instance%:Buffer Node(*)\Foreign pages</Counter>						<!--Memory Performance: Number of pages which are not from NUMA-local memory. This value should be 0. (Source:PAL)-->
	<Counter>\%instance%:General Statistics\Logins/sec</Counter>					<!--SQL Pressure: Login and logout rates should be approximately the same. A login rate higher than the logout rate suggests that the server is not in a steady state, or that applications are not correctly using connection pooling. This could result in an increased load on the server. Solution: Verify if the .NET connection string is using the pooling=true e connection reset=true parameters. Greater than 2 logins per second - this may indicate that applications are not correctly using connection pooling. (Source:PAL)-->
	<Counter>\%instance%:General Statistics\Logouts/sec</Counter>					<!--SQL Pressure: Total number of logouts started per second. Greater than 2 per second indicates that the application is not correctly using connection pooling. (Source:PAL)-->
	<Counter>\%instance%:General Statistics\User Connections</Counter>				<!--**SQL Pressure: Number of users connected to the system. The number of users currently connected to the SQL Server. This should correlate with the Batch Requests per second counter. (Source:PAL)-->
	<Counter>\%instance%:General Statistics\Active Temp Tables</Counter>			<!--SQL Pressure: Number of temporary tables/table variables in use-->
	<Counter>\%instance%:General Statistics\Processes blocked</Counter>				<!--SQL Pressure: Number of currently blocked processes-->
	<Counter>\%instance%:General Statistics\Temp Tables Creation Rate</Counter>		<!--SQL Pressure: Number of temporary tables/table variables created/sec-->
	<Counter>\%instance%:General Statistics\Temp Tables For Destruction</Counter>	<!--SQL Pressure: Number of temporary tables/table variables waiting to be destroyed by the cleanup system thread-->
	<Counter>\%instance%:Memory Manager\Connection Memory (KB)</Counter>			<!--Memory Performance: Specifies the total amount of dynamic memory the server is using for maintaining connections.-->
	<Counter>\%instance%:Memory Manager\Lock Memory (KB)</Counter>					<!--Memory Performance: Specifies the total amount of dynamic memory the server is using for locks.-->
	<Counter>\%instance%:Memory Manager\Log Pool Memory (KB)</Counter>		
	<Counter>\%instance%:Memory Manager\Optimizer Memory (KB)</Counter>				<!--Memory Performance: Specifies the total amount of dynamic memory the server is using for query optimization.-->
	<Counter>\%instance%:Memory Manager\SQL Cache Memory (KB)</Counter>				<!--Memory Performance: Specifies the total amount of dynamic memory the server is using for the dynamic SQL cache.-->
	<Counter>\%instance%:Memory Manager\Memory Grants Pending</Counter>				<!--**Memory Performance: If this counter value is high, then SQL Server is short of buffer memory, which can be caused not simply by a lack of memory but by issues such as oversized memory grants caused by incorrect row counts because your statistics are out-of-date. Current number of processes waiting for a workspace memory grant. Memory Grants Pending records the number of connections that are waiting for memory before they can begin processing a memory intensive query such as a sort or hash operation.  Connections that wait in this state for a long enough time will eventually receive an 8645 error (A time out occurred while waiting for memory resources to execute the query. Rerun the query).  A spid waiting in this state will have a waittype of 0x0040 (RESOURCE_SEMAPHORE) in sysprocesses.  If this counter remains above zero for any significant amount of time then you will need to track down what queries are doing sorts/hashes and check to see if they can get a more efficient plan. Numbers higher than 0 indicate a lack of memory. (Source:PAL)-->
	<Counter>\%instance%:Memory Manager\Target Server Memory (KB)</Counter>			<!--**Memory Performance: (equal to [DBCC MEMORYSTATUS]>[Memory Manager section]>[Target Commited]), Indicates the total amount of dynamic memory SQL Server (include Buffer Pool Cache + Private Bytes) is willing to consume, Any values greater than 500MB is sign of low memory issue. (Source:PAL)-->
	<Counter>\%instance%:Memory Manager\Total Server Memory (KB)</Counter>			<!--**Memory Performance: (equal to [Memory Manager\Database Cache Memory (KB)] + [Memory Manager\Free Memory (KB)] + [Memory Manager\Stolen Server Memory (KB)]), (equal to [DBCC MEMORYSTATUS]>[Memory Manager section]>[VM Commited] + [Locked Pages Allocated]), Indicates the amount of memory currently assigned to SQL Server, If Total Server Memory (KB) is much less than Target Server Memory (KB), then either the SQL Server memory requirement is low, the max server memory configuration parameter of SQL Server is set at too low a value, or the system is in warm-up phase-->
	<Counter>\%instance%:Memory Manager\Database Cache Memory (KB)</Counter>		<!--**Memory Performance: (equal to [Buffer Manager\Database pages]*8KB), (equal to [DBCC MEMORYSTATUS]>[Buffer Pool section]>[Database pages]*8KB), Indication of SQL Server whole Buffer Pool size-->
	<Counter>\%instance%:Memory Manager\Free Memory (KB)</Counter>					<!--**Memory Performance: (equal to [DBCC MEMORYSTATUS]>[Memory Manager]>[Pages Free]). Specifies the amount of committed memory currently not used by the server.-->
	<Counter>\%instance%:Memory Manager\Stolen Server Memory (KB)</Counter>			<!--**Memory Performance: Amount of memory the server is currently using for the purposes other than the database pages. It is used for sorting or hashing operations, or “as a generic memory store for allocations to store internal data structures such as locks, transaction context, and connection information”, also Mem-To-Leave included under this category. This counter value means is that Buffer Pool pages are being utilized/stolen for "other" uses, and not anymore used for holding data and index pages in the BufferPool, This can lead to performance issues and a crunch on the Bufferpool, thereby slowing down overall query performance -->
	<Counter>\%instance%:Memory Manager\Granted Workspace Memory (KB)</Counter>		<!--Memory Performance: this is a subset of "Stolen Server Memory" and "Stolen Server Memory" value include this counter value inside it self. This counter Specifies the total amount of memory currently granted to executing processes, such as hash, sort, bulk copy, and index creation operations.-->
	<Counter>\%instance%:Memory Manager\Reserved Server Memory (KB)</Counter>		<!--Memory Performance: this is a subset of "Stolen Server Memory" and "Stolen Server Memory" value include this counter value inside it self. This counter Indicates the amount of memory the server has reserved for future usage. This counter shows the current unused amount of memory initially granted that is shown in Granted Workspace Memory (KB).-->
	<Counter>\%instance%:Latches\Total Latch Wait Time (ms)</Counter>				<!--**SQL Pressure: Concurrency killer, total latch wait time in milliseconds for latch requests that had to wait in the last second. If the total latch wait time is above 500 milliseconds per each second on average, your SQL Server may be spending too much time waiting on the various latches. It could also be facing resource contention as a result. Review the wait statistics on the server to find the top resources that the SQL Server is waiting on. This value should be less than 500. (Source:PAL)-->
	<Counter>\%instance%:Latches\Latch Waits/sec</Counter>							<!--**SQL Pressure: Concurrency killer, Latch Waits/sec and Total Latch Wait Time (ms) can be correlated to find the average latch wait time.If each latch wait is more than 10 milliseconds on average, your SQL Server may be spending too much time waiting on the various latches. It could also be facing resource contention as a result. This value should be less than 10 on average. (Source:PAL)-->
	<Counter>\%instance%:Locks(*)\Lock Requests/sec</Counter>						<!--**SQL Pressure: Number of new locks and lock conversions requested from the lock manager. This value should tie close to the number of Batch Requests per second. Values greaters than 1000 may indicate queries are pulling large volumes of data thereby accessing large numbers of rows. This value should be less than 1000. (Source:PAL)-->
	<Counter>\%instance%:Locks(*)\Lock Waits/sec</Counter>							<!--**SQL Pressure: Number of lock requests that could not be satisfied immediately and required the caller to wait before being granted the lock. This is a sign that there is some blocking occuring and would be a good baseline measurement of lock waits for load testing. This value should be 0. (Source:PAL)-->
	<Counter>\%instance%:Locks(*)\Lock Wait Time (ms)</Counter>						<!--**SQL Pressure: Total wait time (milliseconds) for locks that started in the last second. Average lock wait time should be below 500 milliseconds per each second on average. Solution: This methods can be used to reduce lock contention and increase overall throughput: Avoid situations in which many processes are attempting to perform updates or inserts on the same data page, Avoid transactions that include user interaction. Because locks are held for the duration of the transaction, a single user can degrade the entire systems performance, Keep transactions that modify data as short as possible. The longer the transaction, the longer the exclusive or update locks are held. This blocks other activity and can lead to an increased number of deadlock situations, Keep transactions in one batch. Unanticipated network problems may delay transactions from completing and thus releasing locks, Avoid pessimistic locking hints such as holdlock whenever possible. They can cause processes to wait even on shared locks, In most cases, you should use SQL Server's default isolation level. The isolation level determines at what point the tradeoffs are made between concurrency and consistency. If you have a strong business need for a higher isolation level, make sure that you evaluate all the tradeoffs and perform thorough testing under a high stress load, Reduce the fillfactor when creating an index to help diminish the chance of random updates requiring the same page. This is especially useful for small tables that are frequently accessed, If you are using DB-Library (DB-Lib), optimistic concurrency control can be specified by using the CCUR_OPTCC setting in dbcursoropen(). This option ensures that update locks are obtained only when a user wants to commit a transaction. (Source:PAL)-->
	<Counter>\%instance%:Locks(*)\Lock Timeouts/sec</Counter>						<!--**SQL Pressure: Number of lock requests that timed out. This does not include requests for NOWAIT locks. A value greater than zero might indicate that user queries are not completing. This value should be 0. (Source:PAL)-->
	<Counter>\%instance%:Locks(*)\Number of Deadlocks/sec</Counter>					<!--**SQL Pressure: Number of lock requests, per second, which resulted in a deadlock. This value should be 0. (Source:PAL)-->
	<Counter>\%instance%:Locks(_Total)\Lock Requests/sec</Counter>					<!--**SQL Pressure: the number of new locks and lock conversions requested from the lock manager per second. A Lock Requests/sec greater than 500 when compared to Batch Request/sec indicates that batches are acquiring a large number of locks. This value should not be greater than 50% of the number of Batch Requests/Sec. Solution: Review high-read queries. In addition, examine the code to determine where to reduce the number of reads by either tuning your application or the database. Lock Requests/sec devided to Batch Request/sec should be less than 500. (Source:PAL)-->
	<Counter>\%instance%:Locks(_Total)\Lock Timeouts/sec</Counter>					<!--**SQL Pressure: Concurrency killer, This counter value should be 0-->
	<Counter>\%instance%:Locks(_Total)\Lock Wait Time (ms)</Counter>				<!--**SQL Pressure: Concurrency killer, A nonzero value for Lock Timeouts/sec and a high value for Lock Wait Time (ms) indicate that excessive blocking is occurring in the database. use sys.dm_exec_query_stats and blocked_process_report Extended event to find root causes-->
	<Counter>\%instance%:Locks(_Total)\Average Wait Time (ms)</Counter>				<!--**SQL Pressure: -->
	<Counter>\%instance%:Locks(_Total)\Number of Deadlocks/sec</Counter>			<!--**SQL Pressure: Concurrency killer, This counter value should be 0-->
	<Counter>\%instance%:Locks\Number of Deadlocks/sec</Counter>					<!--SQL Pressure-->
	<Counter>\%instance%:Transactions\Transactions</Counter>
	<Counter>\%instance%:Transactions\Longest Transaction Running Time</Counter>	<!--SQL Pressure: The longest running time of any transcation in seconds. This counter could indicate a long running statement pulling large amounts of data that normally takes a long time to execute or potentially a blocking condition. (Source:PAL)-->
	<Counter>\%instance%:Deprecated Features(*)\Usage</Counter>
	<Counter>\%instance%:Databases(_Total)\Transactions/sec</Counter>
	<Counter>\%instance%:Databases(_Total)\Write Transactions/sec</Counter>
	<Counter>\%instance%:Databases(_Total)\Active Transactions</Counter>
	<Counter>\%instance%:Databases(*)\Log Bytes Flushed/sec</Counter>				<!--SQL Pressure: Total number of log bytes flushed.-->
	<Counter>\%instance%:Databases(*)\Log Flush Wait Time</Counter>					<!--SQL Pressure: Total wait time (milliseconds) Log Flush Wait Time - This value should ne near 0. (Source:PAL)-->
	<Counter>\%instance%:Databases(*)\Log Flush Waits/sec</Counter>					<!--SQL Pressure: Number of commits waiting on log flush. - This value should ne near 0. (Source:PAL)-->
	<Counter>\%instance%:Databases(*)\Log Flushes/sec</Counter>						<!--SQL Pressure: Number of log flushes-->
	<Counter>\%instance%:Availability Replica(*)\Bytes Received from Replica/sec</Counter>	<!--SQL HA: Bytes Received from Replica/sec: Number of bytes received from the availability replica per second. (Source:PAL)-->
	<Counter>\%instance%:Availability Replica(*)\Bytes Sent to Replica/sec</Counter><!--SQL HA: Number of bytes sent to the remote availability replica per second. (Source:PAL)-->
	<Counter>\%instance%:Database Replica(_Total)\Transaction Delay</Counter>		<!--SQL HA: Number of milliseconds transaction termination waited for acknowledgement per second. When there are multiple secondaries, this is a measure of the total time all transactions waited on the secondary acknowledgement. This counter should be viewed on the Primary replica. (Source:PAL)-->
	<Counter>\%instance%:Database Replica(_Total)\Redone Bytes/sec</Counter>		<!--SQL HA: Amount of log records redone on the secondary database in the last second. This counter can be compared to Log Bytes Received/Sec. If Log Bytes Received/Sec trends greater than Redone Bytes/Sec for sustained periods of time, then redo latency is building up between the primary and secondary replicas, which suggests that counter Redo Bytes Remaining and Recovery Queue is growing. This could indicate Redo is the bottleneck.To measure Recovery Time, divide Recovery Queue by Redone Bytes / Sec. This counter should be viewed on the Secondary replica. (Source:PAL)-->
	<Counter>\%instance%:Database Replica(_Total)\Redo Bytes Remaining</Counter>	<!--SQL HA: The amount of log in kilobytes remaining to be redone to finish the reverting phase. If Redo Bytes Remaining counter is trending up, The redo process could be a bottleneck. This counter should be viewed on the Secondary replica. (Source:PAL)-->
	<Counter>\%instance%:Database Replica(_Total)\Redo blocked/sec</Counter>		<!--SQL HA: Number of times redo gets blocked in the last second. (Source:PAL)-->
	<Counter>\%instance%:Database Replica(_Total)\Log remaining for undo</Counter>	<!--SQL HA: The amount of log in kilobytes remaining to finish the undo phase. This counter should be viewed on the Secondary replica. (Source:PAL)-->
	<Counter>\%instance%:Database Replica(_Total)\Log Send Queue</Counter>			<!--SQL HA: Amount of log records in the log files of the primary database, in kilobytes, that has not yet been sent to the secondary availability replica. This value is sent to the secondary availability replica from the primary availability replica. Queue size does not include FileStream files that are sent to a secondary.  (Source:PAL)-->
	<Counter>\%instance%:Database Replica(*)\Recovery Queue</Counter>				<!--SQL HA: Amount of log records in the log files of the secondary replica that has not yet been redone. The Recovery Queue monitors the progress of the redo of flushed pages. If Recovery Queue is trending up, the redo process could be a bottleneck. For Some versions of AlwaysON, the redo process is single threaded to ensure a consistent read for readable secondaries. This counter should be viewed on the Secondary replica. (Source:PAL)-->
	<Counter>\%instance%:Database Replica(*)\Log Bytes Received/sec</Counter>		<!--SQL HA: Amount of logs received by the availability replica for the database. This counter should be viewed on the Secondary replica. (Source:PAL)-->
	<Counter>\%instance%:Database Replica(*)\Mirrored Write Transactions/sec</Counter>		<!--SQL HA: Number of transactions that wrote to the mirrored database and waited for the log to be sent to the mirror in order to commit, in the last second. This counter is a measure of transactions that are waiting to be hardened to the primary because of Synchronous Availability Mode requiring that they harden at secondary also. When using Asynchronous availability mode this counter is 0. This counter should be viewed on the Primary replica. (Source:PAL)-->
	<Counter>\%instance%:Database Replica(*)\Redone Bytes/sec</Counter>		<!--SQL HA:  (Source:PAL)-->
	<Counter>\%agent%:Jobs\Active jobs</Counter>									<!--SQL Pressure: Number of running jobs. This counter can be used to find out if the current load on the system is potentially being driven from SQL Server Agent execution. (Source:PAL)-->
</PerformanceCounterDataCollector>